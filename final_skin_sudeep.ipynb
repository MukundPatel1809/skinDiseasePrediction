{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libaries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing import image\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to add image path location in metadata\n",
    "def end_to_end_data_prep():\n",
    "    base = '/cxldata/skin_disease_1/'\n",
    "    metadata = pd.read_csv(os.path.join(base,'HAM10000_metadata_orig.csv'))\n",
    "    #metadata.info()\n",
    "    #if we combine data into one directory then no need to mention *\n",
    "    image_path = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                  for x in glob(os.path.join('/cxldata/skin_disease_1/HAM10000_images_draftv1/orig/*.jpg'))}\n",
    "    metadata['path'] = metadata['image_id'].map(image_path.get)\n",
    "    #upload data into dataset with resize 254,254\n",
    "    #metadata['image'] = metadata['path'].map(lambda x: np.asarray(Image.open(x).resize((224,224))))\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for to plot images w.r.t. each category\n",
    "def end_to_end_data_prep_plot(metadata):\n",
    "    n_samples = 5  # number of samples for plotting\n",
    "    # Plotting\n",
    "    fig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\n",
    "    for n_axs, (type_name, type_rows) in zip(m_axs, metadata.sort_values(['dx']).groupby('dx')):\n",
    "        n_axs[0].set_title(type_name)\n",
    "        for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=1234).iterrows()):\n",
    "            c_ax.imshow(c_row['image'])\n",
    "            c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparation for the augmentation\n",
    "def data_prep_augmentation(path):\n",
    "    img = load_img(path, target_size= (224,224))\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentation image generator\n",
    "def data_prep_augmentation_generator(input_image_array,output_dir,output_prefix):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "    i = 0\n",
    "    for batch in datagen.flow(input_image_array, batch_size=1,save_to_dir=output_dir, save_prefix=output_prefix, save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = end_to_end_data_prep()\n",
    "end_to_end_data_prep_plot(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split for data preparation\n",
    "train,test = train_test_split(metadata,stratify=metadata['dx'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first import all data into dataframe then run train_test_split function to split data\n",
    "\n",
    "# total samples are 42650\n",
    "# split with train_test_split (stratify = y,test 0.2 size)\n",
    "# train  - 34120\n",
    "#test - 8530"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train data into csv to overcome processing again n again( 34120 records)\n",
    "train.to_csv('/cxldata/skin_disease_1/sudeep/sudeep_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test data into csv to overcome processing again n again ( 8530 records)\n",
    "\n",
    "test.to_csv('/cxldata/skin_disease_1/sudeep/sudeep_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train data (34120 records)\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv('/cxldata/skin_disease_1/sudeep/sudeep_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34120, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import test data ( 8530 records)\n",
    "import pandas as pd \n",
    "test_df = pd.read_csv('/cxldata/skin_disease_1/sudeep/sudeep_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8530, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created another df because we are not able to run fit model on 34120 records so created another df with 12000 recods\n",
    "train_df1 = train_df[0:12000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [03:45<00:00, 53.16it/s]\n"
     ]
    }
   ],
   "source": [
    "#converting images into numpy array and adding 1 extra dimension(batch) for CNN\n",
    "train_image = []\n",
    "for i in tqdm(range(train_df1.shape[0])):\n",
    "    img = image.load_img(train_df1['path'][i],target_size=[64,64,3])\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    train_image.append(img)\n",
    "\n",
    "X = np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying encoder for y\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "y = train_df1['dx'].values\n",
    "onehotencoder = OneHotEncoder(categories='auto',sparse=False)\n",
    "y = onehotencoder.fit_transform(y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 64, 64, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train and valid dataset\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X,y,stratify=y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9600, 64, 64, 3)\n",
      "(2400, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9600, 7)\n",
      "(2400, 7)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing existing model VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "base_model = keras.applications.vgg16.VGG16(weights=\"imagenet\",\n",
    "                                                  include_top=False,input_shape = (64,64,3))\n",
    "model_t1 = Sequential()\n",
    "model_t1.add(base_model)\n",
    "model_t1.add(Flatten())\n",
    "model_t1.add(Dense(64,activation=\"relu\"))\n",
    "model_t1.add(Dense(7,activation=\"softmax\"))\n",
    "#avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "#output = keras.layers.Dense(7, activation=\"softmax\")(avg)\n",
    "#model = keras.models.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = keras.optimizers.SGD(lr=0.2)\n",
    "model_t1.compile(loss=\"categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model_t1.fit(X_train,y_train,epochs=3,validation_data=(X_valid,y_valid)) #changed from 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t1.save('/cxldata/skin_disease_1/sudeep/1/4_nadam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8530/8530 [02:37<00:00, 54.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# for test dataset\n",
    "train_image = []\n",
    "for i in tqdm(range(test_df.shape[0])):\n",
    "    img = image.load_img(test_df['path'][i],target_size=[64,64,3])\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    train_image.append(img)\n",
    "\n",
    "X_test = np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "y_test = test_df['dx'].values\n",
    "onehotencoder = OneHotEncoder(categories='auto',sparse=False)\n",
    "y_test = onehotencoder.fit_transform(y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('/cxldata/skin_disease_1/sudeep/1/4_nadam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "67/67 [==============================] - 141s 2s/step - loss: 0.3456 - accuracy: 0.9089\n",
      "test loss, test acc: [0.3455950915813446, 0.9089097380638123]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for single image\n",
    "classes = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "img_path1 = '/cxldata/skin_disease_1/HAM10000_images_draftv1/akiec2/akiec_0_9864.jpg'\n",
    "img1 = image.load_img(img_path1,color_mode='rgb', target_size=(64, 64))\n",
    "display(img1)\n",
    "x1 = image.img_to_array(img1)\n",
    "x1.shape\n",
    "# Adding the fouth dimension, for number of images\n",
    "x1 = np.expand_dims(x1, axis=0)\n",
    "\n",
    "x1 = preprocess_input(x1)\n",
    "features1 = model_t1.predict(x1)\n",
    "features1\n",
    "#p = decode_predictions(features)\n",
    "MaxPosition=np.argmax(features1)  \n",
    "prediction_label=classes[MaxPosition]\n",
    "print(prediction_label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rounded_labels=np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_labels[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1038,   10,   28,   10,    8,   17,   10],\n",
       "       [  13,  924,   16,   19,    3,   45,   11],\n",
       "       [  14,   12, 1093,   15,   11,   96,   12],\n",
       "       [   8,   14,   15, 1194,    4,   14,    7],\n",
       "       [   8,    9,   41,    6, 1112,  109,   17],\n",
       "       [   6,   13,   45,   19,   46, 1182,   30],\n",
       "       [   2,    2,    2,    3,    0,    7, 1210]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(rounded_labels, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      1121\n",
      "           1       0.94      0.90      0.92      1031\n",
      "           2       0.88      0.87      0.88      1253\n",
      "           3       0.94      0.95      0.95      1256\n",
      "           4       0.94      0.85      0.89      1302\n",
      "           5       0.80      0.88      0.84      1341\n",
      "           6       0.93      0.99      0.96      1226\n",
      "\n",
      "    accuracy                           0.91      8530\n",
      "   macro avg       0.91      0.91      0.91      8530\n",
      "weighted avg       0.91      0.91      0.91      8530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(rounded_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
