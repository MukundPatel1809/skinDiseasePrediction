{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not needed- to be removed\n",
    "def setUpImport():\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "    from glob import glob\n",
    "    from PIL import Image\n",
    "    from tqdm import tqdm\n",
    "    from keras.preprocessing import image\n",
    "    %matplotlib inline\n",
    "    from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "    from keras.utils.np_utils import to_categorical\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense,Flatten\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to add image path location in metadata\n",
    "def end_to_end_data_prep():\n",
    "    base = '/cxldata/skin_disease_1/skinDisease_data'\n",
    "    metadata = pd.read_csv(os.path.join(base,'HAM10000_metadata.csv'))\n",
    "    #metadata.info()\n",
    "    #if we combine data into one directory then no need to mention *\n",
    "    image_path = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                  for x in glob(os.path.join('/cxldata/skin_disease_1/HAM10000_images_draftv1/','*','*.jpg'))}\n",
    "    metadata['path'] = metadata['image_id'].map(image_path.get)\n",
    "    #upload data into dataset with resize 254,254\n",
    "    #metadata['image'] = metadata['path'].map(lambda x: np.asarray(Image.open(x).resize((224,224))))\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for to plot images w.r.t. each category\n",
    "def end_to_end_data_prep_plot(metadata):\n",
    "    n_samples = 5  # number of samples for plotting\n",
    "    # Plotting\n",
    "    fig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\n",
    "    for n_axs, (type_name, type_rows) in zip(m_axs, metadata.sort_values(['dx']).groupby('dx')):\n",
    "        n_axs[0].set_title(type_name)\n",
    "        for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=1234).iterrows()):\n",
    "            c_ax.imshow(c_row['image'])\n",
    "            c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparation for the augmentation\n",
    "def data_prep_augmentation(path):\n",
    "    img = load_img(path, target_size= (224,224))\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentation image generator\n",
    "def data_prep_augmentation_generator(input_image_array,output_dir,output_prefix):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "    i = 0\n",
    "    for batch in datagen.flow(input_image_array, batch_size=1,save_to_dir=output_dir, save_prefix=output_prefix, save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data split\n",
    "def dataSplit():\n",
    "    \n",
    "    # train test split for data preparation\n",
    "    train,test = train_test_split(metadata,stratify=metadata['dx'],test_size=0.2)\n",
    "    \n",
    "    # save train data into csv to overcome processing again n again( 34120 records)\n",
    "    train.to_csv('/cxldata/skin_disease_1/skinDisease_data/skinDisease_train_main.csv')\n",
    "    \n",
    "    # save test data into csv to overcome processing again n again ( 8530 records)\n",
    "    test.to_csv('/cxldata/skin_disease_1/skinDisease_data/skinDisease_test_main.csv')\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all train data\n",
    "def getTrain_all():\n",
    "    train_df = pd.read_csv('/cxldata/skin_disease_1/skinDisease_data/skinDisease_train_main.csv')\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all test data \n",
    "def getTest_all():\n",
    "    test_df = pd.read_csv('/cxldata/skin_disease_1/skinDisease_data/skinDisease_test_main.csv')\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created another df because we are not able to run fit model on 34120 records so created another df with 12000 recods\n",
    "def getsplittrain(train_df):\n",
    "    train_df1 = train_df[0:12000]\n",
    "    return train_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting images into numpy array and adding 1 extra dimension(batch) for CNN\n",
    "def convertTo4DArray(train_df1):\n",
    "    train_image = []\n",
    "    for i in tqdm(range(train_df1.shape[0])):\n",
    "        img = image.load_img(train_df1['path'][i],target_size=[64,64,3])\n",
    "        img = image.img_to_array(img)\n",
    "        img = img/255\n",
    "        train_image.append(img)\n",
    "    X = np.array(train_image)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying encoder for y\n",
    "def applyEncoderToLabel(train_df1):\n",
    "    y = train_df1['dx'].values\n",
    "    onehotencoder = OneHotEncoder(categories='auto',sparse=False)\n",
    "    y = onehotencoder.fit_transform(y.reshape(-1,1))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model building\n",
    "def buildModelAndTraining(X,y):\n",
    "    base_model = keras.applications.vgg16.VGG16(weights=\"imagenet\",\n",
    "                                                      include_top=False,input_shape = (64,64,3))\n",
    "    model_t1 = Sequential()\n",
    "    model_t1.add(base_model)\n",
    "    model_t1.add(Flatten())\n",
    "    model_t1.add(Dense(64,activation=\"relu\"))\n",
    "    model_t1.add(Dense(7,activation=\"softmax\"))\n",
    "    #avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    #output = keras.layers.Dense(7, activation=\"softmax\")(avg)\n",
    "    #model = keras.models.Model(inputs=base_model.input, outputs=output)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    #optimizer = keras.optimizers.SGD(lr=0.2)\n",
    "    X_train,X_valid,y_train,y_valid = train_test_split(X,y,stratify=y,test_size=0.2)\n",
    "    model_t1.compile(loss=\"categorical_crossentropy\", optimizer=\"nadam\",metrics=[\"accuracy\"])\n",
    "    history = model_t1.fit(X_train,y_train,epochs=3,validation_data=(X_valid,y_valid)) #changed from 5\n",
    "    \n",
    "    model_t1.save('/cxldata/skin_disease_1/skinDisease_data/4_nadam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare test dataset\n",
    "def prepare_test_dataset(X,y):\n",
    "    train_image = []\n",
    "    for i in tqdm(range(test_df.shape[0])):\n",
    "        img = image.load_img(test_df['path'][i],target_size=[64,64,3])\n",
    "        img = image.img_to_array(img)\n",
    "        img = img/255\n",
    "        train_image.append(img)\n",
    "\n",
    "    X_test = np.array(train_image)\n",
    "    y_test = test_df['dx'].values\n",
    "    onehotencoder = OneHotEncoder(categories='auto',sparse=False)\n",
    "    y_test = onehotencoder.fit_transform(y_test.reshape(-1,1))\n",
    "    return X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model\n",
    "def evaluate_model(X_test,y_test):\n",
    "    model = keras.models.load_model('/cxldata/skin_disease_1/skinDisease_data/4_nadam.h5')\n",
    "    print(\"Evaluate on test data\")\n",
    "    results = model.evaluate(X_test, y_test, batch_size=128)\n",
    "    print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the test data- testing\n",
    "def predict_test_data(X_test):\n",
    "    model = keras.models.load_model('/cxldata/skin_disease_1/skinDisease_data/4_nadam.h5')\n",
    "    y_pred=model.predict(X_test, batch_size=128)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "def predict(img_path1):\n",
    "    model = keras.models.load_model('/cxldata/skin_disease_1/skinDisease_data/4_nadam.h5')\n",
    "    # prediction for single image\n",
    "    classes = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "    #img_path1 = '/cxldata/skin_disease_1/HAM10000_images_draftv1/akiec2/akiec_0_9864.jpg'\n",
    "    img1 = image.load_img(img_path1,color_mode='rgb', target_size=(64, 64))\n",
    "    display(img1)\n",
    "    x1 = image.img_to_array(img1)\n",
    "    x1.shape\n",
    "    # Adding the fouth dimension, for number of images\n",
    "    x1 = np.expand_dims(x1, axis=0)\n",
    "\n",
    "    x1 = preprocess_input(x1)\n",
    "    features1 = model.predict(x1)\n",
    "    features1\n",
    "    #p = decode_predictions(features)\n",
    "    MaxPosition=np.argmax(features1)  \n",
    "    prediction_label=classes[MaxPosition]\n",
    "    print('*************prediction_label**********',prediction_label) \n",
    "    return prediction_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "def confusionMatrixAndAccuracySummary(y_pred):\n",
    "    rounded_labels=np.argmax(y_test, axis=1)\n",
    "    y_pred_1=np.argmax(y_pred, axis=1)\n",
    "\n",
    "    print('rounded_labels===>' '\\n',classification_report(rounded_labels, y_pred_1))\n",
    "    cm = confusion_matrix(rounded_labels, y_pred_1)\n",
    "    print('confusion matix===>' '\\n',cm)\n",
    "    \n",
    "    print('-----------------classification_report----------------' '\\n',classification_report(rounded_labels, y_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------end_to_end_data_preparation completed --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------dataSplit completed --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [04:55<00:00, 40.60it/s]\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1120 09:43:15.711226 140636660291392 deprecation.py:506] From /usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------convertTo4DArray completed --------------------\n",
      "--------------------label encoding completed --------------------\n",
      "--------------------model construcrtion and training started --------------------\n",
      "Train on 9600 samples, validate on 2400 samples\n",
      "Epoch 1/3\n",
      "9600/9600 [==============================] - 198s 21ms/sample - loss: 0.8586 - acc: 0.7349 - val_loss: 0.6018 - val_acc: 0.8188\n",
      "Epoch 2/3\n",
      "9600/9600 [==============================] - 196s 20ms/sample - loss: 0.4514 - acc: 0.8761 - val_loss: 0.4115 - val_acc: 0.8850\n",
      "Epoch 3/3\n",
      "9600/9600 [==============================] - 197s 21ms/sample - loss: 0.3557 - acc: 0.9024 - val_loss: 0.3667 - val_acc: 0.8946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/8530 [00:00<03:26, 41.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------model construcrtion and training finished --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8530/8530 [03:11<00:00, 44.62it/s]\n",
      "W1120 09:56:22.740607 140636660291392 deprecation.py:506] From /usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1120 09:56:22.741871 140636660291392 deprecation.py:506] From /usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------evaluation started --------------------\n",
      "Evaluate on test data\n",
      "8530/8530 [==============================] - 134s 16ms/sample - loss: 0.3641 - acc: 0.8951\n",
      "test loss, test acc: [0.36405526781836817, 0.8950762]\n",
      "--------------------evaluation completed --------------------\n",
      "-------------------- confusionMatrixAndAccuracySummary started --------------------\n",
      "rounded_labels===>\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      1121\n",
      "           1       0.96      0.85      0.90      1031\n",
      "           2       0.90      0.84      0.87      1253\n",
      "           3       0.93      0.93      0.93      1256\n",
      "           4       0.93      0.85      0.89      1302\n",
      "           5       0.80      0.87      0.83      1341\n",
      "           6       0.92      0.98      0.95      1226\n",
      "\n",
      "    accuracy                           0.90      8530\n",
      "   macro avg       0.90      0.90      0.90      8530\n",
      "weighted avg       0.90      0.90      0.90      8530\n",
      "\n",
      "confusion matix===>\n",
      " [[1058    4   18    9    7   14   11]\n",
      " [  31  874   16   26    6   37   41]\n",
      " [  35    6 1051   20   22  106   13]\n",
      " [  39   12    7 1167    2   18   11]\n",
      " [  32    7   20   12 1111  106   14]\n",
      " [  18    4   55   23   51 1170   20]\n",
      " [   8    1    0    0    1   12 1204]]\n",
      "-----------------classification_report----------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      1121\n",
      "           1       0.96      0.85      0.90      1031\n",
      "           2       0.90      0.84      0.87      1253\n",
      "           3       0.93      0.93      0.93      1256\n",
      "           4       0.93      0.85      0.89      1302\n",
      "           5       0.80      0.87      0.83      1341\n",
      "           6       0.92      0.98      0.95      1226\n",
      "\n",
      "    accuracy                           0.90      8530\n",
      "   macro avg       0.90      0.90      0.90      8530\n",
      "weighted avg       0.90      0.90      0.90      8530\n",
      "\n",
      "-------------------- confusionMatrixAndAccuracySummary completed --------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing import image\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input,decode_predictions\n",
    "\n",
    "\n",
    "#create function to add image path location in metadata\n",
    "metadata=end_to_end_data_prep()\n",
    "print(\"--------------------end_to_end_data_preparation completed --------------------\")\n",
    "\n",
    "# his is for to plot images w.r.t. each category\n",
    "#########end_to_end_data_prep_plot(metadata)\n",
    "\n",
    "#data split\n",
    "train,test = dataSplit()\n",
    "print(\"--------------------dataSplit completed --------------------\")\n",
    "\n",
    "\n",
    "#get all train data\n",
    "train_df = getTrain_all()\n",
    "\n",
    "#get all test data \n",
    "test_df = getTest_all()\n",
    "\n",
    "#get top 12000 records\n",
    "train_df1 = getsplittrain(train_df)\n",
    "\n",
    "#converting images into numpy array and adding 1 extra dimension(batch) for CNN\n",
    "X = convertTo4DArray(train_df1)\n",
    "print(\"--------------------convertTo4DArray completed --------------------\")\n",
    "\n",
    "#applying encoder for y\n",
    "y = applyEncoderToLabel(train_df1)\n",
    "print(\"--------------------label encoding completed --------------------\")\n",
    "\n",
    "print(\"--------------------model construcrtion and training started --------------------\")\n",
    "#build the model \n",
    "buildModelAndTraining(X,y)\n",
    "print(\"--------------------model construcrtion and training finished --------------------\")\n",
    "\n",
    "#prepare test dataset\n",
    "X_test,y_test = prepare_test_dataset(X,y)\n",
    "\n",
    "print(\"--------------------evaluation started --------------------\")\n",
    "#evaluate the model\n",
    "evaluate_model(X_test,y_test)\n",
    "print(\"--------------------evaluation completed --------------------\")\n",
    "\n",
    "#predict the test data- testing\n",
    "y_pred = predict_test_data(X_test)\n",
    "\n",
    "print(\"-------------------- confusionMatrixAndAccuracySummary started --------------------\")\n",
    "confusionMatrixAndAccuracySummary(y_pred)\n",
    "print(\"-------------------- confusionMatrixAndAccuracySummary completed --------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------prediction started --------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7FE78E378DA0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************prediction_label********** akiec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'akiec'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict\n",
    "print(\"--------------------prediction started --------------------\")\n",
    "img_path1 = '/cxldata/skin_disease_1/HAM10000_images_draftv1/akiec2/akiec_0_9864.jpg'\n",
    "predict(img_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
